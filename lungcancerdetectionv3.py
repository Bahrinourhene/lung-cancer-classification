# -*- coding: utf-8 -*-
"""lungcancerdetectionv3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ob8jek1Fis2Mu8wgrr8CEQp9lOqvcvge

# lung cancer detection project
"""

#!pip install

"""## importing required modules"""

from zipfile import ZipFile
from google.colab import drive

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import keras
from keras import layers
from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D
from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D
from keras.models import Model

        
import keras.backend as K
K.set_image_data_format('channels_last')

from matplotlib.pyplot import imshow
from keras.preprocessing import image
from keras import applications
from keras.models import Sequential
import os,sys
import warnings
warnings.simplefilter("ignore")
from keras.applications.xception import Xception

import cv2
from keras.preprocessing.image import ImageDataGenerator

"""## import dataset"""

# specifying the zip file name
file_name = "/content/drive/MyDrive/python /archive.zip"
file2_name= "/content/drive/MyDrive/python /archivetest.zip"
  
# opening the zip file in READ mode
with ZipFile(file_name, 'r') as zip:
    # extracting all the files
    print('Extracting all the files now...')
    zip.extractall("/content/drive/MyDrive/python /DATA")
with ZipFile(file2_name, 'r') as zip:
    # extracting all the files
    zip.extractall("/content/drive/MyDrive/python /DATA")
    print('Done!')

"""## Check image shape """

img = cv2.imread('/content/drive/MyDrive/python /DATA/Test cases/000001_03_01_088.png')
print(img.shape)
plt.imshow(img)

train_dir = '/content/drive/MyDrive/python /DATA/Data/train'
validation_dir = '/content/drive/MyDrive/python /DATA/Data/valid'
test_dir = '/content/drive/MyDrive/python /DATA/Data/test'

train_datagen = ImageDataGenerator(rescale=1. / 255,
                                       rotation_range=20,  #Rotation range to randomly rotate the image.
                                       width_shift_range=0.2, # Random horizontal shift range
                                       height_shift_range=0.2, #Random vertical shift range %of height
                                       zoom_range=0.2, #Random zoom range
                                       brightness_range=[0.2,1.0]
                                   )
validation_datagen = ImageDataGenerator(rescale=1. / 255,
                                       rotation_range=20,
                                       width_shift_range=0.2,
                                       height_shift_range=0.2,
                                       zoom_range=0.2,
                                       brightness_range=[0.2,1.0]

train_generator = train_datagen.flow_from_directory(train_dir,  # this is the target directory
                                                        target_size=(224, 224),  #all images will be resized to 224x224
                                                        batch_size=5,
                                                        class_mode="categorical")

valid_generator = validation_datagen.flow_from_directory(validation_dir,
                                                                target_size=(224, 224),
                                                                batch_size=5,
                                                                class_mode="categorical")

test_generator = validation_datagen.flow_from_directory(test_dir,
                                                                target_size=(224, 224),
                                                                batch_size=5,
                                                                class_mode="categorical")

"""# Xception model"""

batch_size = 64

from tensorflow.keras.optimizers import Adam
from keras.callbacks import ReduceLROnPlateau

learning_rate_reduction = ReduceLROnPlateau(monitor="accuracy",  #quantity to be monitored
                                            patience=2,  #number of epochs with improvement
                                            verbose=1, 
                                            factor=0.2, # the learning rate will be increase by 0.2
                                            min_lr=0.0001) #lower bound on the learning rate

STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size
STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size

"""## Instantiate a base model with pre-trained weights"""

base_model = Xception(weights='imagenet',# Load weights pre-trained on ImageNet
                      input_shape=(224, 224, 3), # Input equals image shape
                      include_top=False)  # Do not include the ImageNet classifier at the top

"""### Create a new model on top."""

inputs = keras.Input(shape=(224, 224, 3))

# add a global spatial average pooling layer
x = base_model(inputs, training=False) # Freeze the layer

# Convert features of shape `base_model.output_shape[1:]` to vectors
x = keras.layers.GlobalAveragePooling2D()(x)

# add 2 fully-connected layers
x = Dense(1024, activation='relu')(x) # relu torbet bin layer o layer fi lweset
x = Dense(1024, activation='relu')(x)

# and a logistic layer 
predictions =Dense(4, activation='softmax')(x) #final resoult after training

# first: train only the top layers (which were randomly initialized)
# freeze all convolutional Xception layers
for layer in base_model.layers:
    layer.trainable = False
    
# this is the model we will train
xception = Model(inputs, outputs=predictions)

"""#Train the model on new data"""

xception.compile(optimizer = Adam(learning_rate = 0.0001), loss = "categorical_crossentropy", metrics = ['accuracy'])

history = xception.fit_generator(generator=train_generator, #our train dataset
                    steps_per_epoch=STEP_SIZE_TRAIN,  
                    validation_data=valid_generator,  #our valid dataset
                    validation_steps=STEP_SIZE_VALID,
                    epochs=50,
                    verbose=1,
                   callbacks=learning_rate_reduction
)

# summarize history for accuracy (how many time the model succeed)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()
# summarize history for loss (how many time the model failed)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

"""## Evaluation"""

STEP_SIZE_TEST=test_generator.n//test_generator.batch_size

loss, acc = xception.evaluate_generator(generator=test_generator, steps=STEP_SIZE_TEST, verbose=1)

print(loss, acc)